{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from pathlib import Path\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file\n",
    "file_path = Path(\"../data/cleaned_data/cleaned_training_tweets.csv\")\n",
    "\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the DataFrame to test both TextBlob and VaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blob_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the target column\n",
    "text_blob_df = text_blob_df.drop(columns=['target'])\n",
    "text_blob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the target column\n",
    "vader_sentiment_df = vader_sentiment_df.drop(columns=['target'])\n",
    "vader_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run original data set through Bag of Words Vectorization Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Prcoessing and Bag of Word Vectorization using Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
    "text_counts = cv.fit_transform(original_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into trainig and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, original_df['target'], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"Accuracy Score: \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score\n",
    "precision = metrics.precision_score(Y_test, predicted, average='weighted')\n",
    "recall = metrics.recall_score(Y_test, predicted, average='weighted')\n",
    "f1_score = metrics.f1_score(Y_test, predicted, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform sentiment analysis using TextBlob and convert to labels\n",
    "def analyze_sentiment_blob(text):\n",
    "    if isinstance(text, float):\n",
    "        return 'neutral'\n",
    "    analysis = TextBlob(str(text))\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'sentiment_label'\n",
    "text_blob_df['textblob_sentiment'] = text_blob_df['cleaned_text'].apply(analyze_sentiment_blob)\n",
    "text_blob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform sentiment analysis using TextBlob and convert to labels\n",
    "def analyze_sentiment_blob(text):\n",
    "    if isinstance(text, float):\n",
    "        return 'neutral'\n",
    "    analysis = TextBlob(str(text))\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        return 'positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the function to the 'cleaned_text' column and create a new column 'textblob_sentiment'\n",
    "text_blob_df['textblob_sentiment_lables'] = text_blob_df['cleaned_text'].apply(analyze_sentiment_blob)\n",
    "\n",
    "text_blob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blob_df.value_counts('textblob_sentiment_lables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify where to place cleaned data and what to call it\n",
    "cleaned_file_path = '../data/cleaned_data/text_blob_sentiment.csv'\n",
    "\n",
    "#save data using the cleaned file path.\n",
    "text_blob_df.to_csv(cleaned_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textblob_df = pd.read_csv('../data/cleaned_data/text_blob_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run textBlob through the Bag of Words vectorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill any missing values with an empty str\n",
    "textblob_df['cleaned_text'] = textblob_df['cleaned_text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Process the data using bag of words Vectorization-Based Model\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
    "text_counts = cv.fit_transform(textblob_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into trainig and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, textblob_df['textblob_sentiment_lables'], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predicted = MNB.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "from sklearn import metrics\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"Accuracy Score: \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score\n",
    "precision = metrics.precision_score(Y_test, predicted, average='weighted')\n",
    "recall = metrics.recall_score(Y_test, predicted, average='weighted')\n",
    "f1_score = metrics.f1_score(Y_test, predicted, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VaderSentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = SentimentIntensityAnalyzer()\n",
    "#create a function to apply to our data frame\n",
    "def analyze_sentiment_vader (text):    \n",
    "    sentiment_score = sentiment.polarity_scores(text)\n",
    "    return sentiment_score['compound']\n",
    "#apply the created function to the copied vader_sentiment_df data frame    \n",
    "vader_sentiment_df['sentiment_vader'] = vader_sentiment_df['cleaned_text'].apply(analyze_sentiment_vader)\n",
    "vader_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert sentiment scores to labels\n",
    "def sentiment_to_label(score):\n",
    "    if score >= 0.1:\n",
    "        return 'positive'\n",
    "    elif score <= -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the function to the 'sentiment_vader' column and create a new column 'sentiment_label'\n",
    "vader_sentiment_df['vader_sentiment_label'] = vader_sentiment_df['sentiment_vader'].apply(sentiment_to_label)\n",
    "\n",
    "# Display the DataFrame with sentiment labels\n",
    "vader_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment_df.value_counts('sentiment_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify where to place cleaned data and what to call it\n",
    "cleaned_file_path = '../data/cleaned_data/vader_sentiment.csv'\n",
    "\n",
    "#save data using the cleaned file path.\n",
    "vader_sentiment_df.to_csv(cleaned_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_df = pd.read_csv('../data/cleaned_data/vader_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run Vader through the Bag of Words vectorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill any missing values with an empty str\n",
    "vader_df['cleaned_text'] = vader_df['cleaned_text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Process the data using bag of words Vectorization-Based Model\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
    "text_counts = cv.fit_transform(vader_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into trainig and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, vader_df['vader_sentiment_label'], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predicted = MNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"Accuracy Score: \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score\n",
    "precision = metrics.precision_score(Y_test, predicted, average='weighted')\n",
    "recall = metrics.recall_score(Y_test, predicted, average='weighted')\n",
    "f1_score = metrics.f1_score(Y_test, predicted, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the 3 csv files. Bert, Vader, and Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the files\n",
    "vader_df = pd.read_csv(\"../data/cleaned_data/vader_sentiment.csv\")\n",
    "bert_df = pd.read_csv(\"../data/cleaned_data/bert_sentiment_analysis_50000.csv\")\n",
    "textblob_df = pd.read_csv(\"../data/cleaned_data/text_blob_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_df = vader_df.head(15000)\n",
    "textblob_df = textblob_df.head(15000)\n",
    "bert_df = bert_df.head(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df.value_counts('sentiment_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(vader_df, textblob_df, on='cleaned_text', how='inner')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, bert_df, on='cleaned_text', how='inner')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create a new column 'matching_label' with default value 0\n",
    "merged_df['matching_label'] = 0\n",
    "\n",
    "# Conditions to check for matching labels\n",
    "condition1 = (merged_df['vader_sentiment_label'] == merged_df['textblob_sentiment_lables']) & (merged_df['vader_sentiment_label'] == merged_df['sentiment_labels'])\n",
    "condition2 = (merged_df['vader_sentiment_label'] == merged_df['textblob_sentiment_lables']) & (merged_df['vader_sentiment_label'] != merged_df['sentiment_labels'])\n",
    "condition3 = (merged_df['vader_sentiment_label'] != merged_df['textblob_sentiment_lables']) & (merged_df['vader_sentiment_label'] == merged_df['sentiment_labels'])\n",
    "condition4 = (merged_df['vader_sentiment_label'] != merged_df['textblob_sentiment_lables']) & (merged_df['textblob_sentiment_lables'] == merged_df['sentiment_labels'])\n",
    "\n",
    "# Set values based on conditions\n",
    "merged_df['matching_label'] = np.where(condition1, 'All 3 Match',\n",
    "                           np.where(condition2, 'Vader, Textblob Match',\n",
    "                           np.where(condition3, 'Vader, Bert Match',\n",
    "                           np.where(condition4, 'Textblob, Bert Match', 'None Match'))))\n",
    "\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.value_counts('matching_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where all three labels match\n",
    "filtered_df = merged_df[merged_df['matching_label'] != \"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each matching_label category after filtering\n",
    "label_counts = filtered_df['matching_label'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "label_counts.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Matching Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Counts of Matching Labels (Excluding All 3 Match)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
